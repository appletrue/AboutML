## **标量，向量，矩阵和张量**

- **标量（scalar）**：一个标量就是一个单独的数。用斜体表示标量，如 s∈R.
- **向量（vector）**：一个向量是一列数，我们用粗体的小写名称表示向量。比如 x，将向量x 写成方括号包含的纵柱： 

$X=  \begin {bmatrix} x_1\\x_2\\ \vdots \\x_n\\ \end{bmatrix}$

- **矩阵（matrix）**：矩阵是二维数组，我们通常赋予矩阵粗体大写变量名称，比如 A 。如果一个矩阵高度是m，宽度是n，那么说A∈Rm×n 。一个矩阵可以表示如下：

$A= \begin{bmatrix} x_{11} &x_{12}\\ x_{21} & x_{22}\\  \end{bmatrix}$

- **张量（tensor）**：某些情况下，我们会讨论不止维坐标的数组。如果一组数组中的元素分布在若干维坐标的规则网络中，就将其称为张量。用A 表示，如张量中坐标为(i,j,k)的元素记作$A_{i,j,k}$
- **转置（transpose）**：矩阵的转置是以对角线为轴的镜像，这条从左上角到右下角的对角线称为主对角线（main diagonal）。将矩阵A的转置表示为$A^T$。定义如下： $(A^⊤)_{i,j}=A_{j,i}$

$A= \begin{bmatrix} x_{11} &x_{12}\\ x_{21} & x_{22}\\ x_{31} & x_{32} \end{bmatrix} \implies  A^T= \begin{bmatrix} x_{11} &x_{21}&x_{31} \\ x_{21} & x_{22}& x_{32} \end{bmatrix}$

### 线性变换与向量空间

关于线性变换Y=AX

求变量$y_1,y_2,…,y_n$到变量$x_1,x_2,…,x_n$的线性变换相当于求**方阵A 的逆矩阵**。$X=A^{-1}Y$

$\begin{cases}3x + 4y  &= 10 \\5x - 7y  &= 3 \end{cases}$, 

行向量图解法：

$\begin{bmatrix} 3 \\ 5 \end{bmatrix}x + \begin{bmatrix} 4 \\ 7 \end{bmatrix}y = \begin{bmatrix} 10 \\ 3 \end{bmatrix}$

列向量—线性组合

----------------------------------------** 几种空间 ** --------------------------------------

#### 向量空间（线性空间）

$\forall x,y $, $\begin{bmatrix} 3 \\ 5 \end{bmatrix}x + \begin{bmatrix} 4 \\ 7 \end{bmatrix}y =?$组成一个平面

向量空间含义：引申理解

> 象棋的本质是它的行走规则，至于它的棋子是木头的、石头的还是玉的无关紧要。改变了象棋的行走规则它就不是原来的象棋了，但改变棋子它还是象棋。
>
> 向量空间的本质也是它的运算规则，它是定义了两种运算满足八条规则的集合，是对n维向量运算的概括抽象，这一抽象扩充了向量的概念，向量概念不单指有序实数列，还可以是函数、矩阵、多项式、映射等等，所以向量空间的元素究竟是什么就变得不重要了。
>
> 下象棋可以让棋，我可以让你两个马、两个兵或者两个象，但只要其他棋子行走规则不变，它依然是象棋。这就类似由部分向量生成向量空间，向量的“多少”不是本质，本质在于运算规则不变。
>
> [引自：](https://www.zhihu.com/question/21833200/answer/37140675)

哈密顿为了扩充复数概念而发展了四元数，根据四元数发展出向量概念，经格拉斯曼《扩张论》引出了向量空间这一概念，(见图灵出版社《代数的历史》或李文林《数学史》）。

**向量空间的本质是 规则的集合**。向量空间在数学上的「对应概念」是**集合**。

不同的集合，条件不同，规则也不一样。对于空间的理解，要看定义了什么条件，体现什么规则。

#### 欧几里得空间（集合空间）

> 欧式空间呢？欧式几何的关键就在于角度、长度的度量，因此在抽象向量空间中引入长度、角度概念。就如同在象棋中引入棋子之间的距离，角度一样，使其可以度量。
>
> [引自：](https://www.zhihu.com/question/21833200/answer/37140675)

设V是实数域上的线性空间，在V中定义了一个二元实函数，称为内积，记作(α,β),它具有下列性质： 
1) (α,β) = (β,α) 
2) (kα,β) = k(α,β),k∈R 
3) (α+β,γ) = (α,γ)+(β,γ), γ∈V 
4) (α,α)≥0,当且仅当, α=0时，(α,α)=0 
其中，α,β,γ是V中任意向量，k是任意实数。这样的线性空间V称为欧几里得空间，简称为欧式空间。

直观的从定义上来来看，欧式空间和线性空间的区别就是前者引入了**内积**的概念。

但由于这概念的引入，欧式空间可以引入两种操作。这使得它有别于线性空间。

在定义了内积的基础上，引入长度的概念：非负实数$\sqrt {(\overline α,\overline α)}$称为向量α的长度，记作|α|

在内积的基础上，和长度的基础上，引入夹角的概念：非零向量α,β的夹角$<α,β>=arccos{\frac {(α,β)}{|α||β|}}$

简单来说。欧式空间就是在向量空间的基础上引入了“长度”和“角度”的度量。从而可进一步引入正交的概念。欧式空间是一个内积空间。

#### 希尔伯特空间([From wiki](https://zh.wikipedia.org/wiki/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E7%A9%BA%E9%97%B4))

在数学里，希尔伯特空间即完备的内积空间，也就是说一个带有内积的完备向量空间。是有限维欧几里得空间的一个推广，使之不局限于实数的情形和有限的维数，但又不失完备性（而不像一般的非欧几里得空间那样破坏了完备性）。

内积空间——其上有距离和角的概念（及由此引申而来的正交性与垂直性的概念）。

完备空间——其上所有的柯西序列会收敛到此空间里的一点，从而微积分中的大部分概念都可以无障碍地推广到希尔伯特空间中。

希尔伯特空间为基于任意正交系上的多项式表示的傅立叶级数和[傅立叶变换](https://zh.wikipedia.org/wiki/%E5%82%85%E7%AB%8B%E5%8F%B6%E5%8F%98%E6%8D%A2)提供了一种有效的表述方式，而这也是泛函分析的核心概念之一。

希尔伯特空间是公设化数学和量子力学的关键性概念之一。

-------------------------------------

## 矩阵和向量相乘

- **矩阵乘法**：矩阵运算中最重要的操作之一。两个矩阵A和B 的矩阵乘积(matrix product)是第三个矩阵C 。矩阵乘法中A 的列必须和 B的行数相同。即如果矩阵 A的形状是 m×n，矩阵B的形状是 n×p，那么矩阵 C的形状就是 m×p。即 C=A×B

其中的乘法操作定义为:  $ C_{i,j} = \sum_k A_{i,k} B_{k,j}$

矩阵乘积服从分配律，结合律，但是矩阵乘法没有交换律，

- 矩阵乘积的转置 (向量也是一种特殊的矩阵) 

$ (AB)^T = B^T A^T$  ===*===$\bf x ^T y = (x^T y)^T = y^T x$

- **内积：——点积，数量积**

**点积**（**Dot Product**）是两个向量上的函数并返回一个标量的二元运算，结果是欧几里得空间的标准**内积**。两个向量的点积写作**a·b**，**数量积**及**标量积**。

两个相同维数的向量x和y的点积可看作是矩阵乘积$ x^Ty$。 点积是内积的一种特殊形式。

- **外积：——叉积**

向量的另一种乘法是外积（Cross Product或Vector Product），写作**a×b**。

叉积（Cross product）是一种在向量空间中向量的二元运算。与点积不同，它的运算结果是一个向量而不是一个标量。

两个向量的叉积写作${a}\times {b} $，也称作外积（Outer product）或向量积（Vector product）。

**叉积与原来的两个向量都垂直。**

## 范数

需要衡量一个向量的大小，在机器学习中，使用称为范数（norm）的函数来衡量向量大小，形式上， Lp范数如下：其中$|| x||_p = (\sum_i |x_i|^p)^\frac{1}{p}$，其中 p∈R,p≥1

范数是将向量映射到非负值的函数。直观上来说，向量 x的范数就是衡量从原点到 x的距离。更严格来说，范数满足下列性质的函数：

$f(x)=0 \implies x =0$

$ f(x+y) \leq f(x) + f(y)$

$\forall \alpha \in \Bbb R,  f(\alpha x) = |\alpha|f(x)$

当 p=2时， L2被称作欧几里得范数（Euclidean norm）。它表示从原点出发到向量x确定的点的欧几里得距离。L2范数常被用来衡量向量的大小，因为它便于求导计算（如对向量中每个元素的导数只取决于对应的元素，但是它也有缺陷，即它在原点附近增长得十分缓慢），可以简单用点积$x^Tx$来计算。

当p=1时，称为L1范数，是向量元素绝对值之和；

当p=0时，上面的定义没有包含，称为0范数，定义为向量非零元素的数量

max范数（max norm）：这个范数表示向量中具有最大幅度得元素的绝对值，用L∞范数表示，形式为：

$||x||_\infty = max |x_i|$

两个向量的点积(dot product)也可以用范数来表示。具体地 $\bf x \top y = ||x||_2||y||_2 \cos \theta$

矩阵的范数（matrix norm）,最常用的就是 Frobenius norm, $\mid\mid A\mid\mid_{F} = \left ( \sum_i \sum_j {\mid a_{ij}\mid}^2 \right )^{frac 1 2}$
